<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Metropolis Algorithm</title>
    <meta name="description" content="An intuitive introduction to the Metropolis algorithm including interactive simulators and source code.">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@500;700&family=Inter:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <nav id="floating-nav" class="floating-nav">
        <div class="floating-nav__header">
            <span class="floating-nav__title">Nav</span>
        </div>
        <ul class="floating-nav__list" id="floating-nav-list"></ul>
        <div class="floating-nav__links">
            <a href="https://linear-regression.metropolis-algorithm.com/" target="_blank" class="floating-nav__btn">Linear Regression Simulator</a>
            <a href="https://change-point-detection.metropolis-algorithm.com/" target="_blank" class="floating-nav__btn">Change Point Simulator</a>
            <a href="https://github.com/almostmachines/metropolis-cpd-script" target="_blank" class="floating-nav__btn floating-nav__btn--alt">Change Point Algorithm</a>
        </div>
    </nav>
    <button id="floating-nav-toggle" class="floating-nav-toggle" aria-label="Toggle navigation">
        <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
            <rect y="3" width="20" height="2" rx="1" fill="currentColor"/>
            <rect y="9" width="20" height="2" rx="1" fill="currentColor"/>
            <rect y="15" width="20" height="2" rx="1" fill="currentColor"/>
        </svg>
    </button>
    <article>

        <svg class="logo" viewBox="0 0 800 200" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="The Metropolis Algorithm">
            <defs>
                <filter id="cyan-glow">
                    <feGaussianBlur stdDeviation="4" result="blur"/>
                    <feComposite in="SourceGraphic" in2="blur" operator="over"/>
                </filter>
                <filter id="purple-glow">
                    <feGaussianBlur stdDeviation="3" result="blur"/>
                    <feComposite in="SourceGraphic" in2="blur" operator="over"/>
                </filter>
                <filter id="soft-glow">
                    <feGaussianBlur stdDeviation="6" result="blur"/>
                    <feMerge>
                        <feMergeNode in="blur"/>
                        <feMergeNode in="SourceGraphic"/>
                    </feMerge>
                </filter>
                <linearGradient id="line-fade-r" x1="0" y1="0" x2="1" y2="0">
                    <stop offset="0%" stop-color="#22d3ee" stop-opacity="0.8"/>
                    <stop offset="100%" stop-color="#22d3ee" stop-opacity="0"/>
                </linearGradient>
                <linearGradient id="line-fade-l" x1="1" y1="0" x2="0" y2="0">
                    <stop offset="0%" stop-color="#a956ff" stop-opacity="0.8"/>
                    <stop offset="100%" stop-color="#a956ff" stop-opacity="0"/>
                </linearGradient>
                <linearGradient id="walk-grad" x1="0" y1="0" x2="1" y2="0">
                    <stop offset="0%" stop-color="#22d3ee" stop-opacity="0.1"/>
                    <stop offset="40%" stop-color="#22d3ee" stop-opacity="0.6"/>
                    <stop offset="60%" stop-color="#a956ff" stop-opacity="0.6"/>
                    <stop offset="100%" stop-color="#a956ff" stop-opacity="0.1"/>
                </linearGradient>
            </defs>

            <!-- random walk path (Metropolis chain motif) -->
            <polyline points="80,160 120,145 160,150 200,130 240,135 280,115 320,120 360,105 400,100 440,95 480,85 520,90 560,70 600,65 640,60 680,55 720,50"
                fill="none" stroke="url(#walk-grad)" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" opacity="0.5"/>
            <!-- walk dots -->
            <g fill="#22d3ee" opacity="0.3">
                <circle cx="80" cy="160" r="2"/>
                <circle cx="160" cy="150" r="2"/>
                <circle cx="240" cy="135" r="2"/>
                <circle cx="320" cy="120" r="2"/>
                <circle cx="400" cy="100" r="2.5"/>
            </g>
            <g fill="#a956ff" opacity="0.3">
                <circle cx="480" cy="85" r="2"/>
                <circle cx="560" cy="70" r="2"/>
                <circle cx="640" cy="60" r="2"/>
                <circle cx="720" cy="50" r="2"/>
            </g>

            <!-- decorative corner accents -->
            <polyline points="30,30 30,15 45,15" fill="none" stroke="#22d3ee" stroke-width="1.5" opacity="0.6"/>
            <polyline points="770,30 770,15 755,15" fill="none" stroke="#a956ff" stroke-width="1.5" opacity="0.6"/>
            <polyline points="30,170 30,185 45,185" fill="none" stroke="#22d3ee" stroke-width="1.5" opacity="0.4"/>
            <polyline points="770,170 770,185 755,185" fill="none" stroke="#a956ff" stroke-width="1.5" opacity="0.4"/>

            <!-- horizontal accent lines -->
            <line x1="50" y1="88" x2="220" y2="88" stroke="url(#line-fade-r)" stroke-width="1"/>
            <line x1="580" y1="88" x2="750" y2="88" stroke="url(#line-fade-l)" stroke-width="1"/>

            <!-- diamond accent left of title -->
            <polygon points="55,70 65,60 75,70 65,80" fill="none" stroke="#22d3ee" stroke-width="1" opacity="0.7" filter="url(#cyan-glow)"/>
            <!-- diamond accent right of title -->
            <polygon points="725,70 735,60 745,70 735,80" fill="none" stroke="#a956ff" stroke-width="1" opacity="0.7" filter="url(#purple-glow)"/>

            <!-- main title -->
            <text x="400" y="72" text-anchor="middle" font-family="'Orbitron', sans-serif" font-weight="700" font-size="46" fill="#adffea" filter="url(#soft-glow)">THE METROPOLIS</text>

            <!-- subtitle -->
            <text x="400" y="112" text-anchor="middle" font-family="'Orbitron', sans-serif" font-weight="500" font-size="22" fill="#c68fff" letter-spacing="12" filter="url(#purple-glow)">ALGORITHM</text>

            <!-- thin separator dots -->
            <g fill="#22d3ee" opacity="0.4">
                <circle cx="310" cy="130" r="1.5"/>
                <circle cx="330" cy="130" r="1"/>
                <circle cx="345" cy="130" r="1.5"/>
            </g>
            <g fill="#a956ff" opacity="0.4">
                <circle cx="455" cy="130" r="1.5"/>
                <circle cx="470" cy="130" r="1"/>
                <circle cx="490" cy="130" r="1.5"/>
            </g>
        </svg>

        <h1>Hello world</h1>

        <p class="lead">To follow this guide you only need to know what a <strong>Normal distribution</strong> is and what an <strong>integral</strong> is, by the end you will hopefully understand the <strong>Metropolis algorithm</strong> intuitively (the what, the why and the how), and learn about <strong>statistical modelling</strong> and <strong>Bayesian statistics</strong> along the way.</p>

        <h2>Introduction</h2>

        <p>Metropolis is a prince of an algorithm.</p>

        <p>It's like a drunk person stumbling home, and as they wander erratically in a homeward direction they come to understand a complex problem beyond the capability of a cogent scholar.</p>

        <p>And it's the wandering, the erratic path, that can solve the impossible.</p>

        <h2>A glimpse</h2>

        <div class="textWithImage">
            <div class="textWithImage__text">
                <p>To see the Metropolis algorithm in action, try this <a href="https://linear-regression.metropolis-algorithm.com" target="_blank">interactive simulator.</a></p>

                <p>The yellow square is some unknown part of reality, an entity or process floating in probability space. The entity has three <em>attributes</em>, each one is represented by an axis in the 3D space. In a real world setting, the location of the yellow square (the values of its attributes) would be unknown to us. All we have are some scattered, noisy observations.</p>

                <p>The cyan circle is our starting point, representing our initial <em>hypothesis</em> about the value of each attribute.</p>
            </div>

            <picture class="textWithImage__image">
                <img alt="Plot of 3D probability space" src="./3dplot.webp">
            </picture>
        </div>

        <div class="textWithImage">
            <div class="textWithImage__text">
                <p>Press the <strong>Full Auto</strong> button in the sidebar and watch the algorithm locate the yellow square. You can rotate, pan and zoom using your mouse controls / trackpad / touch. Press <strong>Reset</strong> and then press <strong>Full Auto</strong> a few more times. Observe that the algorithm takes a different trajectory every time. It&rsquo;s a homing missile that finds the target and encloses it within its probability cloud <em>(posterior distribution)</em>.</p>
            </div>

            <picture class="textWithImage__image">
                <img alt="Simulator control buttons" src="./buttons.webp">
            </picture>
        </div>

        <div class="textWithImage">
            <div class="textWithImage__text">
                <p>The <strong>Results</strong> section shows this plot. The yellow line is the actual entity that we're trying to capture, in this experiment it's a linear process. Around the yellow line are white dots representing individual observations of the process. The three attributes are: the slope of the line, the y-axis intercept of the line, and the noise <em>(standard deviation)</em> of the observations.</p>

                <p>The cyan dashed line is our best estimate of the yellow line based on the probability cloud <em>(posterior distribution)</em>. Click <strong>Reset</strong> and <strong>Full Auto</strong> again and watch the cyan line converge upon the yellow line as the algorithm progresses.</p>

                <p>The <strong>Posterior Report</strong> underneath contains our best estimates of the attributes and our uncertainty about them <em>(95% credible intervals)</em>, as well as their true values.</p>
            </div>

            <picture class="textWithImage__image">
                <img alt="Simulator results report" src="./results.webp">
            </picture>
        </div>

        <div class="textWithImage">
            <div class="textWithImage__text">
                <p>We don't want the 'contrails' to form part of our final belief, so we usually ignore the first N number of steps. Change the <strong>Burn-in</strong> setting in the sidebar to a value of 70 and press <strong>Full Auto</strong> again.</p>
            </div>

            <picture class="textWithImage__image">
                <img alt="Simulator results report" src="./burn-in-setting.webp">
            </picture>
        </div>

        <p>To understand how the algorithm works, we&rsquo;re going to look at a more interesting problem.</p>

        <h2>A problem</h2>

        <p>Suppose that we are monitoring the levels of dissolved oxygen (mg/L) in stream water. Samples collected at random times over a 24 hour period suggest that there was a change-point in the early afternoon:</p>

        <canvas id="observations-plot" width="720" height="400"></canvas>
        <script>
        (function() {
            const canvas = document.getElementById('observations-plot');
            const ctx = canvas.getContext('2d');
            const dpr = window.devicePixelRatio || 1;

            function resize() {
                const cssW = canvas.parentElement.clientWidth;
                const cssH = Math.round(cssW * 400 / 720);
                canvas.style.width = cssW + 'px';
                canvas.style.height = cssH + 'px';
                canvas.width = cssW * dpr;
                canvas.height = cssH * dpr;
                ctx.setTransform(dpr, 0, 0, dpr, 0, 0);
                return { w: cssW, h: cssH };
            }

            const obs = [{"t":0.229,"o":13.021},{"t":0.329,"o":11.874},{"t":0.407,"o":12.200},{"t":0.429,"o":12.656},{"t":0.533,"o":12.271},{"t":0.652,"o":11.974},{"t":0.764,"o":13.608},{"t":0.770,"o":12.323},{"t":0.791,"o":11.488},{"t":1.239,"o":11.588},{"t":1.257,"o":11.964},{"t":1.261,"o":11.948},{"t":1.264,"o":12.096},{"t":1.353,"o":13.095},{"t":1.378,"o":12.029},{"t":1.425,"o":11.303},{"t":1.496,"o":11.458},{"t":1.567,"o":12.126},{"t":1.593,"o":10.560},{"t":1.767,"o":11.756},{"t":2.056,"o":10.967},{"t":2.122,"o":12.119},{"t":2.180,"o":12.751},{"t":2.325,"o":12.364},{"t":2.429,"o":13.016},{"t":2.448,"o":11.566},{"t":2.462,"o":14.198},{"t":2.536,"o":11.279},{"t":2.571,"o":11.549},{"t":2.604,"o":11.770},{"t":2.638,"o":12.862},{"t":2.686,"o":11.593},{"t":2.775,"o":11.979},{"t":2.809,"o":13.354},{"t":2.978,"o":13.609},{"t":3.018,"o":11.541},{"t":3.127,"o":11.685},{"t":3.231,"o":10.827},{"t":3.358,"o":12.019},{"t":3.368,"o":12.370},{"t":3.400,"o":12.907},{"t":3.527,"o":12.265},{"t":3.608,"o":14.039},{"t":3.634,"o":12.337},{"t":3.840,"o":12.726},{"t":3.840,"o":12.323},{"t":3.905,"o":12.034},{"t":4.023,"o":12.231},{"t":4.047,"o":12.448},{"t":4.126,"o":13.180},{"t":4.288,"o":11.098},{"t":4.356,"o":12.982},{"t":4.516,"o":12.468},{"t":4.549,"o":13.263},{"t":4.564,"o":12.761},{"t":4.603,"o":10.190},{"t":4.678,"o":12.569},{"t":4.689,"o":11.282},{"t":4.693,"o":13.716},{"t":4.708,"o":12.461},{"t":4.823,"o":11.998},{"t":4.883,"o":12.504},{"t":4.909,"o":12.643},{"t":5.071,"o":12.150},{"t":5.105,"o":12.428},{"t":5.116,"o":11.563},{"t":5.132,"o":13.263},{"t":5.167,"o":13.613},{"t":5.173,"o":11.577},{"t":5.308,"o":11.444},{"t":5.394,"o":10.508},{"t":5.404,"o":12.161},{"t":5.463,"o":10.780},{"t":5.513,"o":11.497},{"t":5.568,"o":11.003},{"t":5.812,"o":13.265},{"t":5.847,"o":12.391},{"t":5.879,"o":12.280},{"t":5.904,"o":11.866},{"t":5.938,"o":11.697},{"t":6.223,"o":11.163},{"t":6.228,"o":12.140},{"t":6.276,"o":11.808},{"t":6.428,"o":11.999},{"t":6.452,"o":12.478},{"t":6.473,"o":12.234},{"t":6.480,"o":12.942},{"t":6.489,"o":12.385},{"t":6.502,"o":11.835},{"t":6.519,"o":11.705},{"t":6.535,"o":12.266},{"t":6.710,"o":12.119},{"t":6.750,"o":11.684},{"t":6.873,"o":13.074},{"t":6.877,"o":11.925},{"t":6.906,"o":13.841},{"t":6.935,"o":10.827},{"t":6.982,"o":11.479},{"t":7.125,"o":12.207},{"t":7.171,"o":11.672},{"t":7.205,"o":13.816},{"t":7.264,"o":13.683},{"t":7.340,"o":12.518},{"t":7.501,"o":11.176},{"t":7.507,"o":12.198},{"t":7.701,"o":11.643},{"t":7.707,"o":10.757},{"t":7.720,"o":11.015},{"t":7.723,"o":12.225},{"t":7.743,"o":11.503},{"t":7.804,"o":12.183},{"t":7.811,"o":11.479},{"t":7.868,"o":12.691},{"t":7.928,"o":12.253},{"t":8.210,"o":10.980},{"t":8.452,"o":13.036},{"t":8.463,"o":12.220},{"t":8.654,"o":12.156},{"t":8.685,"o":11.036},{"t":8.709,"o":12.736},{"t":8.767,"o":11.999},{"t":8.906,"o":13.621},{"t":8.978,"o":11.998},{"t":8.986,"o":13.009},{"t":9.157,"o":12.241},{"t":9.174,"o":11.428},{"t":9.350,"o":12.490},{"t":9.421,"o":10.765},{"t":9.435,"o":12.220},{"t":9.443,"o":9.770},{"t":9.452,"o":11.357},{"t":9.495,"o":10.747},{"t":9.550,"o":12.884},{"t":9.650,"o":13.465},{"t":9.831,"o":13.245},{"t":9.889,"o":11.900},{"t":10.051,"o":11.143},{"t":10.069,"o":11.330},{"t":10.135,"o":12.551},{"t":10.162,"o":11.870},{"t":10.265,"o":12.366},{"t":10.451,"o":13.204},{"t":10.459,"o":12.433},{"t":10.486,"o":11.628},{"t":10.654,"o":12.967},{"t":10.771,"o":13.272},{"t":11.019,"o":12.886},{"t":11.286,"o":11.819},{"t":11.297,"o":12.185},{"t":11.299,"o":12.040},{"t":11.359,"o":11.696},{"t":11.507,"o":11.354},{"t":11.582,"o":11.211},{"t":11.649,"o":12.366},{"t":11.792,"o":12.197},{"t":11.857,"o":10.185},{"t":11.884,"o":12.403},{"t":11.931,"o":13.170},{"t":12.073,"o":11.614},{"t":12.104,"o":13.754},{"t":12.254,"o":12.009},{"t":12.318,"o":11.145},{"t":12.355,"o":11.151},{"t":12.581,"o":12.463},{"t":12.685,"o":13.305},{"t":12.776,"o":12.473},{"t":12.788,"o":11.220},{"t":12.927,"o":12.997},{"t":12.941,"o":13.515},{"t":12.989,"o":12.270},{"t":13.001,"o":11.803},{"t":13.029,"o":12.782},{"t":13.038,"o":11.314},{"t":13.042,"o":11.901},{"t":13.115,"o":12.991},{"t":13.136,"o":12.710},{"t":13.170,"o":11.118},{"t":13.274,"o":13.680},{"t":13.537,"o":12.398},{"t":13.693,"o":11.851},{"t":13.870,"o":13.073},{"t":14.202,"o":11.971},{"t":14.293,"o":11.101},{"t":14.487,"o":11.293},{"t":14.500,"o":12.913},{"t":14.647,"o":12.321},{"t":14.658,"o":13.791},{"t":14.663,"o":15.135},{"t":14.788,"o":13.957},{"t":14.840,"o":13.189},{"t":14.886,"o":13.937},{"t":14.941,"o":12.974},{"t":15.015,"o":11.592},{"t":15.215,"o":14.480},{"t":15.280,"o":13.160},{"t":15.338,"o":13.664},{"t":15.374,"o":13.047},{"t":15.384,"o":13.415},{"t":15.393,"o":12.033},{"t":15.459,"o":13.492},{"t":15.462,"o":13.067},{"t":15.529,"o":12.409},{"t":15.671,"o":14.375},{"t":15.763,"o":14.557},{"t":15.938,"o":14.303},{"t":16.026,"o":13.248},{"t":16.071,"o":14.105},{"t":16.109,"o":13.373},{"t":16.335,"o":13.880},{"t":16.363,"o":11.297},{"t":16.505,"o":12.000},{"t":16.640,"o":12.971},{"t":16.722,"o":14.763},{"t":16.798,"o":13.067},{"t":16.831,"o":13.081},{"t":16.878,"o":12.931},{"t":16.899,"o":12.373},{"t":17.259,"o":13.374},{"t":17.316,"o":13.388},{"t":17.389,"o":14.307},{"t":17.493,"o":12.693},{"t":17.496,"o":12.769},{"t":17.665,"o":14.150},{"t":17.739,"o":12.965},{"t":17.789,"o":12.886},{"t":17.821,"o":13.153},{"t":17.846,"o":13.424},{"t":17.884,"o":13.736},{"t":17.915,"o":12.153},{"t":17.976,"o":12.834},{"t":17.992,"o":13.760},{"t":18.000,"o":12.904},{"t":18.000,"o":14.133},{"t":18.098,"o":13.620},{"t":18.191,"o":12.568},{"t":18.194,"o":13.948},{"t":18.219,"o":11.824},{"t":18.286,"o":12.736},{"t":18.387,"o":13.608},{"t":18.455,"o":12.079},{"t":18.548,"o":12.203},{"t":18.597,"o":13.029},{"t":18.610,"o":11.252},{"t":18.676,"o":11.828},{"t":18.757,"o":13.008},{"t":18.766,"o":14.443},{"t":18.897,"o":13.274},{"t":19.185,"o":13.827},{"t":19.221,"o":14.757},{"t":19.300,"o":14.051},{"t":19.320,"o":11.972},{"t":19.445,"o":13.044},{"t":19.452,"o":14.208},{"t":19.674,"o":13.931},{"t":19.781,"o":13.701},{"t":19.869,"o":13.174},{"t":20.080,"o":14.194},{"t":20.095,"o":12.250},{"t":20.159,"o":12.818},{"t":20.188,"o":14.465},{"t":20.540,"o":13.566},{"t":20.567,"o":12.614},{"t":20.583,"o":12.802},{"t":20.682,"o":12.408},{"t":20.714,"o":13.345},{"t":20.733,"o":13.013},{"t":20.771,"o":12.664},{"t":20.811,"o":11.897},{"t":20.916,"o":12.306},{"t":20.922,"o":12.768},{"t":21.069,"o":13.356},{"t":21.127,"o":13.827},{"t":21.190,"o":14.036},{"t":21.459,"o":12.363},{"t":21.492,"o":14.552},{"t":21.571,"o":12.355},{"t":21.642,"o":13.232},{"t":21.681,"o":14.198},{"t":21.745,"o":12.987},{"t":21.766,"o":15.056},{"t":21.784,"o":11.989},{"t":21.953,"o":12.699},{"t":21.970,"o":13.643},{"t":22.097,"o":12.533},{"t":22.258,"o":13.347},{"t":22.476,"o":13.007},{"t":22.588,"o":11.046},{"t":22.765,"o":12.887},{"t":22.874,"o":15.311},{"t":22.951,"o":14.653},{"t":23.040,"o":14.353},{"t":23.548,"o":12.384},{"t":23.624,"o":14.580},{"t":23.658,"o":13.044},{"t":23.695,"o":13.550},{"t":23.703,"o":13.376},{"t":23.728,"o":13.474},{"t":23.775,"o":13.726},{"t":23.794,"o":13.666},{"t":23.942,"o":13.095}].map(d => ({ time_hours: d.t, oxygen_level_mg_per_l: d.o }));

            function draw() {
                const { w, h } = resize();

                const pad = { top: 20, right: 24, bottom: 48, left: 56 };
                const plotW = w - pad.left - pad.right;
                const plotH = h - pad.top - pad.bottom;

                const xMin = 0, xMax = 24;
                const yVals = obs.map(d => d.oxygen_level_mg_per_l);
                const yDataMin = Math.floor(Math.min(...yVals));
                const yDataMax = Math.ceil(Math.max(...yVals));
                const yMin = yDataMin - 0.5;
                const yMax = yDataMax + 0.5;

                function toX(v) { return pad.left + (v - xMin) / (xMax - xMin) * plotW; }
                function toY(v) { return pad.top + (1 - (v - yMin) / (yMax - yMin)) * plotH; }

                ctx.clearRect(0, 0, w, h);

                // grid lines
                ctx.strokeStyle = '#1e293b';
                ctx.lineWidth = 1;
                for (let x = 0; x <= 24; x += 4) {
                    const px = Math.round(toX(x)) + 0.5;
                    ctx.beginPath(); ctx.moveTo(px, pad.top); ctx.lineTo(px, pad.top + plotH); ctx.stroke();
                }
                for (let y = yDataMin; y <= yDataMax; y++) {
                    const py = Math.round(toY(y)) + 0.5;
                    ctx.beginPath(); ctx.moveTo(pad.left, py); ctx.lineTo(pad.left + plotW, py); ctx.stroke();
                }

                // axes
                ctx.strokeStyle = '#cbd5e1';
                ctx.lineWidth = 1.5;
                ctx.beginPath();
                ctx.moveTo(pad.left, pad.top);
                ctx.lineTo(pad.left, pad.top + plotH);
                ctx.lineTo(pad.left + plotW, pad.top + plotH);
                ctx.stroke();

                // tick labels
                const sans = "'Inter', sans-serif";
                ctx.fillStyle = '#7c8da6';
                ctx.textAlign = 'center';
                ctx.textBaseline = 'top';
                const tickFont = Math.max(10, Math.min(12, w * 0.018));
                ctx.font = tickFont + 'px ' + sans;
                for (let x = 0; x <= 24; x += 4) {
                    ctx.fillText(x + 'h', toX(x), pad.top + plotH + 6);
                }
                ctx.textAlign = 'right';
                ctx.textBaseline = 'middle';
                for (let y = yDataMin; y <= yDataMax; y++) {
                    ctx.fillText(y.toFixed(0), pad.left - 8, toY(y));
                }

                // axis labels
                const labelFont = Math.max(11, Math.min(18, w * 0.02));
                ctx.font = labelFont + 'px ' + sans;
                ctx.fillStyle = '#cbd5e1';
                ctx.textAlign = 'center';
                ctx.textBaseline = 'top';
                ctx.fillText('Time (hours)', pad.left + plotW / 2, pad.top + plotH + 26);

                ctx.save();
                ctx.translate(16, pad.top + plotH / 2);
                ctx.rotate(-Math.PI / 2);
                ctx.textAlign = 'center';
                ctx.textBaseline = 'bottom';
                ctx.fillText('Dissolved O\u2082 (mg/L)', 0, 0);
                ctx.restore();

                // data points
                const r = Math.max(2.5, Math.min(4, w * 0.005));
                ctx.fillStyle = 'rgba(34, 211, 238, 0.7)';
                for (const d of obs) {
                    const cx = toX(d.time_hours);
                    const cy = toY(d.oxygen_level_mg_per_l);
                    ctx.beginPath();
                    ctx.arc(cx, cy, r, 0, Math.PI * 2);
                    ctx.fill();
                }
            }

            draw();
            window.addEventListener('resize', draw);
        })();
        </script>

        <p><strong>We want to find out:</strong></p>

        <ul>
            <li>when did the change-point most likely occur, and a credible interval (Bayesian equivalent of a confidence interval)</li>
            <li>what was the most likely magnitude of the change, and a credible interval</li>
        </ul>

        <p><strong>We're going to construct a Bayesian model for the data:</strong></p>

        <ul>
            <li>a Bayesian model allows us to answer questions like <em>"what is the probability that the change-point occurred between 4:40pm and 4:50pm?"</em></li>
            <li>Bayesian approaches can provide a more complete understanding of complex (high dimensional) problems</li>
            <li>Bayesian modelling is a common use case for the Metropolis algorithm</li>
        </ul>

        <h2>The model</h2>

        <p>We propose a model for the oxygen level consisting of the unknown change-point time $\tau$ in fractional hours (e.g. 14.5 is 2:30pm) and two normal distributions of oxygen levels (mg/L) with unknown means $\mu_1$ <em>(the mean oxygen level before $\tau$)</em> and $\mu_2$ <em>(the mean oxygen level after $\tau$)</em>. Each unknown attribute of the underlying reality $\tau$, $\mu_1$, $\mu_2$, is a model parameter. For the sake of keeping the model parameters within 3 dimensions, the real standard deviation $\sigma$ of oxygen levels is a known constant of +/- 0.9 mg/L. The model of oxygen level $l$ at time $t$ can be expressed as:</p>

        $$l_t \sim
        \begin{cases}
        \operatorname{Normal}(\mu_1, 0.9^2) &amp; \text{if } t &lt; \tau \\
        \operatorname{Normal}(\mu_2, 0.9^2) &amp; \text{if } t \ge \tau
        \end{cases}$$

        <blockquote><p>There exists some time <strong>τ</strong> where the mean oxygen level shifted. Before <strong>τ</strong>, observations come from $\operatorname{Normal}(\mu_1, 0.9^2)$. After <strong>τ</strong>, they come from $\operatorname{Normal}(\mu_2, 0.9^2)$.</p></blockquote>

        <p>The challenge is to estimate $\tau$, $\mu_1$​ and $\mu_2$ given the data, ideally we would like to do this using Bayes Theorem.</p>

        <div class="callout">
            <p class="callout-title">Note</p>
            <p>We <em>assume</em> that the model is true, the challenge is to find the correct values of the parameters. For the purpose of our example the model will <em>actually</em> be true &mdash; the process which generates the observed data will indeed be two Normal distributions and a change point. In a real world situation we might want to compare our model against other models, including a model which has no change point (the null hypothesis). Instead of claiming that models are true or false, we say that there are models which are better or worse at describing and predicting reality.</p>
        </div>

        <h2>A new simulator</h2>

        <div class="textWithImage">
            <div class="textWithImage__text">
                <p>Have a go with <a href="https://change-point-detection.metropolis-algorithm.com/" target="_blank">this simulator</a> for our change-point model.</p>
                <p>The <strong>Results</strong> section shows a plot of the observational data and the real and estimated values of $\tau$, $\mu_1$, $\mu_2$ and the <strong>effect size</strong> ($\mu_2 - \mu_1$).</p>
            </div>

            <picture class="textWithImage__image">
                <img alt="Simulator results report" src="./change-point-results.webp">
            </picture>
        </div>

        <h2>Bayes Theorem</h2>

        <p>The data is constant and known. The real values of $\tau, \mu_1$ and $\mu_2$ are unknown, we will vary their hypothetical values and calculate the probability of each combination to build a probability distribution for all possible hypotheses. Each unique combination of values for $\tau, \mu_1$ and $\mu_2$ forms a hypothesis $\theta_i$ in the set of hypotheses under consideration $\theta$. This will allow us to find the most likely hypothesis (the most likely values of $\tau, \mu_1$ and $\mu_2$.)</p>

        <p>Bayes Theorem relates three functions that depend on $\theta$ and a constant factor that involves the data alone.</p>

        $$p(\theta \mid \text{data}) = \frac{p(\text{data} \mid \theta) \cdot p(\theta)}{p(\text{data})}$$

        <p>$p(\theta \mid \text{data})$ <strong>the posterior distribution</strong> &mdash; the probability distribution of hypotheses $\theta$ given (conditional on) the data &mdash; <em>this is what we want to obtain.</em></p>

        <p>$p(\text{data} \mid \theta)$ <strong>the likelihood function</strong> &mdash; the likelihood of observing the data conditional on a given hypothesis $\theta$.</p>

        <div class="callout">
            <p class="callout-title">Likelihood versus probability</p>
            <p>If we held the hypothesis $\theta$ constant and calculated $p(\text{data} \mid \theta)$ for all possible $\text{data}$ sets then $p(\text{data} \mid \theta)$ would be a probability distribution because the integral over $\text{data}$ would always be equal to 1. But because we are holding $\text{data}$ constant and the integral over $\theta$ <strong>does not</strong> always equal 1, $p(\text{data} \mid \theta)$ expresses a likelihood (a score) not a probability, this is why we call it a likelihood function and not a probability distribution.</p>
            <p>We can use ratios of likelihoods to express the probability of one outcome relative to another, but not their absolute probabilities.</p>
        </div>

        <p>$p(\theta)$ <strong>the prior distribution</strong> &mdash; the probability distribution of hypotheses $\theta$ given our beliefs before seeing the data. Imagine that we haven't seen the data, in our state of ignorance what would our beliefs about time $\tau$ and the means $\mu_1$ and $\mu_2$ be? We need to express those beliefs as a probability distribution.</p>

        <p>$p(\text{data})$ <strong>the evidence</strong> &mdash; how probable is the data in general regardless of which hypothesis is true? $p(\text{data})$ is calculated by integrating the probability of observing the data given a hypothesis weighted by the probability of the given hypothesis itself.</p>

        $$p(\mathrm{data}) = \int p(\mathrm{data}\mid \theta) \cdot p(\theta)\, d\theta$$

        <p>This is the constant, normalisation factor which turns the product of the <strong>likelihood function</strong> and the <strong>prior probability distribution</strong> from being a likelihood ratio into the <strong>posterior probability distribution</strong>.</p>

        <blockquote><p>Bayes Theorem restated &mdash; Given the data, the probability of a hypothesis equals how likely the observed data would be if the hypothesis were true, multiplied by the plausibility of the hypothesis in general (without seeing the data), divided by how likely the observed data is overall (regardless of which hypothesis is true.)</p></blockquote>

        <h3>Practical limitations on using Bayes Theorem</h3>

        <p>The integral for the evidence $p(\text{data})$ is often a stumbling block.</p>

        <p>Ideally we would like to compute the exact values of integrals by deriving their analytical, closed-form solutions:</p>

        $$
            \int x^2 \, dx = \frac{1}3x^3 + C
            \\
            \int_{2}^{5} x^2 \, dx = (\frac{1}3 \cdot 5^3 + C) - (\frac{1}3 \cdot 2^3 + C) = 39
        $$

        <p>When finding a closed-form solution is analytically intractable we can use numerical integration to find an inexact solution. The above example could be solved by computing <em>&ldquo;the area under the curve&rdquo;</em>:</p>

        $$\int_{2}^{5} x^{2}\,dx \approx \sum_{i=1}^{n} f(x_i^{*})\,\Delta x$$

        <p>We would like an analytical solution for $p(\text{data})$:</p>

        $$p(\mathrm{data}) = \int p(\mathrm{data}\mid \theta) \cdot p(\theta)\, d\theta$$

        <p>In our model this is a three-dimensional integral:</p>

        $$p(\mathrm{data}) \;=\; \iiint p(\mathrm{data}\mid \tau,\mu_1,\mu_2)\, p(\tau)\, p(\mu_1)\, p(\mu_2)\, d\tau\, d\mu_1\, d\mu_2$$

        <p>For our simple model, this is in fact analytically tractable. Very often it isn't. For example, we could (but we won't) acknowledge that negative oxygen levels are not physically possible and represent that condition in our model by using a LogNormal instead of a Normal distribution. That minor change would make $p(\text{data})$ analytically intractable.</p>

        <p>If we <em>did do that</em>, we might then use numerical integration <em>(quadrature)</em>: 1) we split the 3-dimensional space into a grid of many small blocks, 2) we calculate $p(\mathrm{data}\mid \tau,\mu_1,\mu_2)\, p(\tau)\, p(\mu_1)\, p(\mu_2)$ by plugging in the values of $\tau$, $\mu_1$ and $\mu_2$ for each grid block and multiplying by the block volume, and 3) we sum the calculations over all grid blocks.</p>

        <p>With just three dimensions (parameters) that is also easily doable.</p>

        <p>Numerical integration rapidly becomes infeasible as the number of parameters increases, typically beyond 5&ndash;10 parameters. Numerically integrating over 7 parameters with a low grid resolution of 20 points per parameter is 1.3 billion computations. Increase that to 10 parameters and it becomes 10 trillion computations.</p>

        <p>Another limitation is that numerical integration struggles to accurately represent a complex posterior distribution (e.g. skewed, many modes).</p>

        <p><strong>When $p(\text{data})$ is analytically intractable and numerical computation is too expensive or the posterior distribution is too complex, an alternative is to use a Markov chain Monte Carlo method like the Metropolis algorithm.</strong></p>

        <h2>The Metropolis algorithm</h2>

        <h3>The posterior odds</h3>

        <p>Recall Bayes Theorem:</p>

        $$p(\theta \mid \text{data}) = \frac{p(\text{data} \mid \theta) \cdot p(\theta)}{p(\text{data})}$$

        <p>If we divide Bayes theorem for any hypothesis $\theta_2$ by Bayes theorem for any other hypothesis $\theta_1$ the normalisation factor $p(\text{data})$ cancels out:</p>

        $$\begin{aligned}
        \frac{p(\theta_2\mid \text{data})}{p(\theta_1\mid \text{data})} &amp;=\frac{p(\text{data} \mid \theta_2) \cdot p(\theta_2)}{p(\text{data})} \cdot\frac{p(\text{data})}{p(\text{data} \mid \theta_1) \cdot p(\theta_1)} \\
        \\
        &amp;= \frac{p(\text{data}\mid \theta_2)}{p(\text{data}\mid \theta_1)} \cdot \frac{p(\theta_2)}{p(\theta_1)}
        \end{aligned}$$

        <p>Some new terminology:</p>

        $$\underbrace{\frac{p(\theta_2\mid \text{data})}{p(\theta_1\mid \text{data})}}_{\text{posterior odds}}=\underbrace{\frac{p(\text{data}\mid \theta_2)}{p(\text{data}\mid \theta_1)}}_{\text{likelihood ratio}}\cdot\underbrace{\frac{p(\theta_2)}{p(\theta_1)}}_{\text{prior odds}}$$

        <p>The <strong>posterior odds</strong> is the ratio of how much more likely one hypothesis is versus another (the ratio of their posterior probability densities). We can calculate this without ever needing to calculate the normalisation factor $p(\text{data})$.</p>

        <p>The <strong>likelihood ratio</strong> is a measure of how strongly the evidence supports one hypothesis versus another.</p>

        <p>The <strong>prior odds</strong> is how much more feasible one hypothesis is versus another in general, it's our prior belief without seeing the data.</p>

        <h3>The algorithm</h3>

        <ol>
            <li>Select an initial current hypothesis $\theta_\text{current}$ by choosing values for parameters $\tau$, $\mu_1$ and $\mu_2$ anywhere in the model probability space (this initial starting position is often informed by the data).</li>
            <li>Propose a new hypothesis $\theta_\text{proposal}$: select new values for the parameters $\tau$, $\mu_1$ and $\mu_2$ by picking a random value within a defined range <em>(a proposal width)</em> around each of the existing values for $\tau$, $\mu_1$ and $\mu_2$ in $\theta_\text{current}$.</li>
            <li><p>Calculate the <strong>posterior odds</strong> for $\theta_\text{proposal}$ over $\theta_\text{current}$.</p>

                $$\frac{p(\theta_\text{proposal}\mid \text{data})}{p(\theta_\text{current}\mid \text{data})}=\frac{p(\text{data}\mid \theta_\text{proposal})}{p(\text{data}\mid \theta_\text{current})}\cdot\frac{p(\theta_\text{proposal})}{p(\theta_\text{current})}$$
            </li>
            <li>
                <p>In this step we choose to accept either $\theta_\text{proposal}$ or $\theta_\text{current}$ as hypothesis $\theta_\text{accepted}$:</p>
                <ul>
                    <li>If $\theta_\text{proposal}$ is <em>more</em> likely than $\theta_\text{current}$ (posterior odds &ge; 1) then $\theta_\text{accepted}=\theta_\text{proposal}$</li>
                    <li>
                        <p>If $\theta_\text{proposal}$ is <em>less</em> likely (posterior odds &lt; 1), we use a random number generator to accept one of the hypotheses by chance. The probability of accepting $\theta_\text{proposal}$ is set to the posterior odds and therefore the probability of accepting $\theta_\text{current}$ is 100% &minus; the posterior odds (in practise we'll be using fractional probabilities, so 1 - the posterior odds).</p>
                        <div class="example-block">
                            <p>E.g. if the posterior odds = 0.8:</p>
                            <p>=&gt; set an 80% chance of selecting $\theta_\text{accepted} = \theta_\text{proposal}$</p>
                            <p>=&gt; there's a 20% chance of selecting $\theta_\text{accepted} = \theta_\text{current}$</p>
                            <p><strong>This is the crucial part of the algorithm: even though $\theta_\text{proposal}$ is less likely (80% as likely as $\theta_\text{current}$), there's an 80% chance that we'll accept it anyway</strong></p>
                        </div>
                    </li>
                </ul>
            </li>
            <li>Record $\theta_\text{accepted}$ (parameter values).</li>
            <li>Jump back to step 2), set $\theta_\text{current}$ to the value of $\theta_\text{accepted}$ and create a new $\theta_\text{proposal}$.</li>
            <li>Repeat this loop until there are enough (many!) records.</li>
        </ol>

        <p>Each recorded hypothesis $\theta_\text{accepted}$ is a sample from an approximation to the <strong>posterior distribution</strong> and the samples converge to the true posterior distribution $p(\theta \mid \text{data})$ as the number of samples approaches infinity. This process allows us to construct the posterior distribution without ever knowing the $p(\text{data})$ normalisation factor.</p>

        <p>It's the ability to jump to less likely locations in the hypothesis space <em>(when the posterior odds &lt; 1 and we accept $\theta_\text{proposal}$)</em> that constructs the posterior distribution. If we always accepted the most likely hypothesis out of $\theta_\text{proposal}$ and $\theta_\text{current}$ we would create a speed running hill climb to the most likely hypothesis (mode) of the posterior distribution, and although this point value is of interest, the process wouldn't give us the posterior <em>distribution</em> itself as it wouldn't sample the full probability space &mdash; we would have the mode but no estimation of its uncertainty. A hill climb also has greater risk of getting stuck in a local maximum if the distribution has multiple modes, i.e. it wouldn't be able to map a multi modal distribution.</p>

        <h3>Markov chain Monte Carlo</h3>

        <p>You'll often see the Metropolis algorithm referred to as Markov chain Monte Carlo or MCMC for short.</p>

        <p>A Markov chain is any sequence where the next state depends only on the current state, not on how you got there. At each step, we propose a move based on where we are now, evaluate whether to accept based on current versus proposed, and move (or stay). The entire history of where we've been is irrelevant to what happens next.</p>

        <p>The "Monte Carlo" part refers to the randomness — we're using random sampling to explore the space by accepting/rejecting proposals.</p>

        <h3>Worked example for oxygen levels</h3>

        <p>We need to derive the posterior odds equation used in the proposal step:</p>

        $$\underbrace{\frac{p(\theta_{\text{proposal}}\mid \text{data})}{p(\theta_\text{current}\mid \text{data})}}_{\text{posterior odds}}=\underbrace{\frac{p(\text{data}\mid \theta_\text{proposal})}{p(\text{data}\mid \theta_\text{current})}}_{\text{likelihood ratio}}\cdot\underbrace{\frac{p(\theta_\text{proposal})}{p(\theta_\text{current})}}_{\text{prior odds}}$$

        <h4>Natural logarithms</h4>

        <p>We will be taking the natural logarithm of the equation for the posterior odds.</p>

        <p>Probabilistic computing often involves multiplying fractional probabilities many times over, and the result can get very small very fast &mdash; too small for the computer's representation of floating point numbers. For this reason, and because it often simplifies the mathematical representations, calculations are done in log space.</p>

        <div class="callout">
            <p class="callout-title">Logarithm rules</p>
            $$\log(a \cdot b) = \log(a) + \log(b)
            \\
            \log(a / b) = \log(a) - \log(b)$$
        </div>

        <p>Taking natural logs of both sides, the posterior odds equation becomes:</p>

        $$\begin{aligned}
        \ln p(\theta_\text{proposal} \mid \text{data})
        -
        \ln p(\theta_\text{current} \mid \text{data})
        &amp;=
        \ln p(\text{data} \mid \theta_\text{proposal})
        -
        \ln p(\text{data} \mid \theta_\text{current})\\\\
        &amp;+
        \ln p(\theta_\text{proposal})
        -
        \ln p(\theta_\text{current})
        \end{aligned}$$

        <h4>1) The prior odds</h4>

        $$\frac{p(\theta_\text{proposal})}{p(\theta_\text{current})}$$

        <p>The prior odds is the ratio of the prior distribution function applied to each hypothesis.</p>

        <p>$p(\theta)$ <strong>the prior distribution</strong> &mdash; the probability distribution of hypotheses $\theta$ given our beliefs before seeing the data.</p>

        <p>What are our beliefs before seeing the data?</p>

        <h5>The time of the change-point $\tau$</h5>

        <p>We have no reason to believe that the change point occurring at time $\tau_1$ is more or less likely than any other time $\tau_2$. Therefore we will model our prior belief as all times being equally likely by using a continuous uniform distribution for $\tau$ where $N$ is the total number of hours in the data.</p>

        $$\tau \sim \operatorname{Uniform}(0, N)$$

        <h5>The mean oxygen levels $\mu_1$ and $\mu_2$ before and after the change-point $\tau$</h5>

        <p>Prior to seeing the data we have no knowledge of the sign or the magnitude of the change, so we'll represent that state of ignorance by setting $\mu_1$ and $\mu_2$ to the same value.</p>

        <p>For our belief about the most likely value of the mean we would draw from our experience, or general public knowledge, or historical data from the stream in question. For this experiment we'll set it to $\mu_1 = 15.0\text{ mg/L}$ and $\mu_2 = 15.0\text{ mg/L}$.</p>

        <p>Our beliefs would also acknowledge that the values of $\mu$ would tail off the further we get from the most likely value. We have no reason to believe that the distribution is skewed, so we'll use a symmetrical distribution.</p>

        <p>Under these conditions the Normal distribution would be a suitable representation of our prior beliefs. We'll choose a standard deviation of +/- 5.0 mg/L, this places our prior belief as being 95% confident that $\mu_1$ and $\mu_2$ are somewhere between 5.2 mg/L and 24.8 mg/L.</p>

        $$\mu_1 \sim \mathrm{Normal}(15.0, 5.0^2)
        \\
        \mu_2 \sim \mathrm{Normal}(15.0, 5.0^2)$$

        <h5>Putting it together</h5>

        <p>Now we can construct the prior distribution $p(\theta)$ for our model.</p>

        <p>Because the parameters in our prior distribution are independent (what we believe about $\tau$ has no impact on what we believe about $\mu_1$ or $\mu_2$) the prior distribution can be expressed as the product of the prior distributions of each model parameter (the multiplication rule for independent probabilities):</p>

        $$p(\theta) = p(\tau) \cdot p(\mu_1) \cdot p(\mu_2)$$

        <p>$\tau$ is distributed uniformly over the time period of the data.</p>

        $$\tau \sim \operatorname{Uniform}(0, N)
        \\
        p(\tau) = \frac{1}{24}$$

        <p>The mean oxygen levels are Normally distributed:</p>

        $$\mu_1 \sim \mathrm{Normal}(15.0, 5.0^2)
        \\
        \mu_2 \sim \mathrm{Normal}(15.0, 5.0^2)
        \\
        p(\mu)=\frac{1}{\sigma\sqrt{2\pi}}\cdot\exp\!\left(-\frac{(\mu-M)^2}{2\sigma^2}\right),\quad \sigma=5.0,\; M=15.0
        \\
        p(\mu_1)=\frac{1}{5.0\sqrt{2\pi}}\cdot\exp\!\left(-\frac{(\mu_1-15.0)^2}{2\cdot5.0^2}\right)
        \\
        p(\mu_2)=\frac{1}{5.0\sqrt{2\pi}}\cdot\exp\!\left(-\frac{(\mu_2-15.0)^2}{2\cdot5.0^2}\right)$$

        <p>The prior distribution becomes:</p>

        $$\begin{aligned}
        p(\theta) &amp;= p(\tau) \cdot p(\mu_1) \cdot p(\mu_2)\\\\
        &amp;=\frac{1}{24}\cdot\frac{1}{5.0^2\cdot{2\pi}}\cdot\exp\!\left(-\frac{(\mu_1-15.0)^2}{2\cdot5.0^2}\right)\cdot\exp\!\left(-\frac{(\mu_2-15.0)^2}{2\cdot5.0^2}\right)
        \end{aligned}$$

        <p>Now we can express the prior odds (the constant factor cancels out):</p>

        $$\frac{p(\theta_\text{proposal})}{p(\theta_\text{current})} = \frac{
        \exp\!\left(-\frac{(\mu_1^{\text{proposal}}-15.0)^2}{2\cdot5.0^2}\right)\cdot\exp\!\left(-\frac{(\mu_2^{\text{proposal}}-15.0)^2}{2\cdot5.0^2}\right)
        }{
        \exp\!\left(-\frac{(\mu_1^{\text{current}}-15.0)^2}{2\cdot5.0^2}\right)\cdot\exp\!\left(-\frac{(\mu_2^{\text{current}}-15.0)^2}{2\cdot5.0^2}\right)
        }$$

        <p>We want this in log form:</p>

        $$\begin{aligned}
        \ln \! \frac{p(\theta_\text{proposal})}{p(\theta_\text{current})}
        &amp;=
        \ln p(\theta_\text{proposal})
        -
        \ln p(\theta_\text{current})
        \\\\
        &amp;=
        -\frac{(\mu_1^{\text{proposal}}-15.0)^2}{2\cdot5.0^2}
        -\frac{(\mu_2^{\text{proposal}}-15.0)^2}{2\cdot5.0^2}
        \\\\
        &amp;+\frac{(\mu_1^{\text{current}}-15.0)^2}{2\cdot5.0^2}
        +\frac{(\mu_2^{\text{current}}-15.0)^2}{2\cdot5.0^2}
        \end{aligned}$$

        <p>The above equation for the feasibility of one hypothesis versus another makes intuitive sense.</p>

        <p>We stated that we have no reason to believe that any change-point time $\tau$ is more likely than another: $\tau$ doesn't appear in the equation.</p>

        <p>We stated that we have no reason to believe that the pre- change-point mean $\mu_1$ is greater or less than the post- change-point mean $\mu_2$ so we set a ballpark guess of 15.0 mg/L for both. The feasibility of a hypothesis then depends only on how far its values of $\mu_1$ and $\mu_2$ are from 15.0 mg/L.</p>

        <div class="callout">
            <p class="callout-title">Note on the properties of natural logarithms</p>
            <p>If the logarithm is negative then the <strong>prior odds</strong> is less than 1: <em>the <strong>proposal hypothesis</strong> is less likely than the <strong>current hypothesis</strong> according to our prior beliefs.</em></p>
            <p>If the logarithm is 0 or positive then the <strong>prior odds</strong> is greater than or equal to 1: <em>the <strong>proposal hypothesis</strong> is at least as likely than the <strong>current hypothesis</strong> according to our prior beliefs..</em></p>
            $$\ln \! \frac{p(\theta_\text{proposal})}{p(\theta_\text{current})}
            \begin{cases}
            &lt; 0, &amp; 0 &lt; \frac{p(\theta_\text{proposal})}{p(\theta_\text{current})} &lt; 1,\\
            = 0, &amp; \frac{p(\theta_\text{proposal})}{p(\theta_\text{current})} = 1,\\
            &gt; 0, &amp; \frac{p(\theta_\text{proposal})}{p(\theta_\text{current})} &gt; 1.
            \end{cases}$$
        </div>

        <p>The further away from 15.0 mg/L that the means for $\theta_\text{proposal}$ become, the less positive or more negative the right-hand side of the log-form equation becomes. This implies a smaller value for the prior odds in the left-hand side, expressing reduced belief in $\theta_\text{proposal}$ relative to $\theta_\text{current}$:</p>

        $$\frac{p(\theta_\text{proposal})}{p(\theta_\text{current})}$$

        <p>Equivalently, the further away from 15.0 mg/L that the $\theta_\text{current}$ means become, the less negative or the more positive the right-hand side of the equation and the larger the value of the prior odds, expressing increasing belief in $\theta_\text{proposal}$ versus $\theta_\text{current}$.</p>

        <h4>2) The likelihood ratio</h4>

        $$\frac{p(\text{data}\mid \theta_\text{proposal})}{p(\text{data}\mid \theta_\text{current})}$$

        <p>The likelihood ratio is the ratio of the likelihood scores for our two hypotheses given the data: the likelihood function for our model applied to each hypothesis.</p>

        <p>$p(\text{data} \mid \theta)$ <strong>the likelihood function</strong> &mdash; the likelihood of observing the data conditional on a given hypothesis $\theta$.</p>

        <p>Our model for the data is that before $\tau$ the oxygen level follows a Normal distribution with mean $\mu_1$ and after $\tau$ it follows a Normal distribution with mean $\mu_2$.</p>

        <p>Recall that we said for the purpose of this example, $\sigma$ is a constant and we know its true value of +/- 0.9 mg/L.</p>

        $$l_t \sim
        \begin{cases}
        \operatorname{Normal}(\mu_1, 0.9^2) &amp; \text{if } t &lt; \tau \\
        \operatorname{Normal}(\mu_2, 0.9^2) &amp; \text{if } t \ge \tau
        \end{cases}$$

        <p>$l_t$ is a continuous variable representing the oxygen level at any time $t$. We want the probability density for each observation $\text{data}_i$ at time $t_i$ given the model parameters $\tau$, $\mu_1$ and $\mu_2$, which is just the Normal probability density function:</p>

        $$f(\text{data}_i \mid \tau,\mu_1,\mu_2)=
        \begin{cases}
        \dfrac{1}{\sqrt{2\pi}\cdot0.9}\exp\!\left(-\dfrac{(\text{data}_i-\mu_1)^2}{2\cdot0.9^2}\right), &amp; \text{if } t_i &lt; \tau,\\[8pt]
        \dfrac{1}{\sqrt{2\pi}\cdot0.9}\exp\!\left(-\dfrac{(\text{data}_i-\mu_2)^2}{2\cdot0.9^2}\right), &amp; \text{if } t_i \ge \tau.
        \end{cases}$$

        <p>The likelihood function then is the product of all the probability densities for the complete set of observations.</p>

        $$\begin{aligned}
        p(\text{data} \mid \theta^{(\tau, \mu_1, \mu_2)})
        &amp;= \prod_{i}f(\text{data}_i \mid \tau,\mu_1,\mu_2)
        \\
        &amp;=\prod_{i}
        \dfrac{1}{\sqrt{2\pi}\cdot0.9}
        \cdot
        \prod_{i:\,t_i&lt;\tau}
        \exp\!\left(-\frac{(\text{data}_i-\mu_1)^2}{2\cdot0.9^2}\right)\cdot
        \prod_{i:\,t_i\ge\tau}\exp\!\left(-\frac{(\text{data}_i-\mu_2)^2}{2\cdot0.9^2}\right)
        \end{aligned}$$

        <p>Now we can express the likelihood ratio (the constant factor cancels out):</p>

        $$\frac{p(\text{data}\mid \theta_\text{proposal})}
        {p(\text{data}\mid \theta_\text{current})}
        =
        \frac
        {
        \prod_{i:\,t_i&lt;\tau^\text{proposal}}\exp\!\left(-\frac{(\text{data}_i-\mu_1^\text{proposal})^2}{2\cdot0.9^2}\right)\cdot
        \prod_{i:\,t_i\ge\tau^\text{proposal}}\exp\!\left(-\frac{(\text{data}_i-\mu_2^\text{proposal})^2}{2\cdot0.9^2}\right)
        }{
        \prod_{i:\,t_i&lt;\tau^\text{current}}\exp\!\left(-\frac{(\text{data}_i-\mu_1^\text{current})^2}{2\cdot0.9^2}\right)\cdot
        \prod_{i:\,t_i\ge\tau^\text{current}}\exp\!\left(-\frac{(\text{data}_i-\mu_2^\text{current})^2}{2\cdot0.9^2}\right)
        }$$

        <p>We take logs of both sides:</p>

        $$\begin{aligned}
        \ln
        \!
        \left(
        \frac
        {p(\text{data}\mid \theta_\text{proposal})}
        {p(\text{data}\mid \theta_\text{current})}
        \right)
        &amp;=
        \sum_{i:\,t_i&lt;\tau^\text{current}}
        \!
        \frac{(\text{data}_i-\mu_1^{(\text{current})})^2}
        {2\cdot0.9^2}
        +
        \sum_{i:\,t_i\ge\tau^\text{current}}
        \!
        \frac{(\text{data}_i-\mu_2^{(\text{current})})^2}
        {2\cdot0.9^2}
        \\\\
        &amp;-
        \sum_{i:\,t_i&lt;\tau^\text{proposal}}
        \!
        \frac{(\text{data}_i-\mu_1^{(\text{proposal})})^2}
        {2\cdot0.9^2}
        -
        \sum_{i:\,t_i\ge\tau^\text{proposal}}
        \!
        \frac{(\text{data}_i-\mu_2^{(\text{proposal})})^2}
        {2\cdot0.9^2}
        \end{aligned}$$

        <p>This result again makes intuitive sense. Recall that for the <strong>prior odds ratio</strong>, the further that our proposed mean $\mu_1^{(\text{proposal})}$ was from our prior beliefs, the smaller the odds ratio expressing reduced belief in $\theta_\text{proposal}$. A similar thing is happening here for our <strong>likelihood ratio</strong>, except that this time it's the distance of $\mu_1^{(\text{proposal})}$ from the $\text{data}$.</p>

        <h4>3) The posterior odds</h4>

        <p>Now we have everything we need to calculate the <strong>posterior odds</strong> used in step 3) of the algorithm.</p>

        $$\underbrace{\frac{p(\theta_{\text{proposal}}\mid \text{data})}{p(\theta_\text{current}\mid \text{data})}}_{\text{posterior odds}}=\underbrace{\frac{p(\text{data}\mid \theta_\text{proposal})}{p(\text{data}\mid \theta_\text{current})}}_{\text{likelihood ratio}}\cdot\underbrace{\frac{p(\theta_\text{proposal})}{p(\theta_\text{current})}}_{\text{prior odds}}$$

        <p>Taking logs:</p>

        $$\begin{aligned}
        \ln p(\theta_\text{proposal} \mid \text{data})
        -
        \ln p(\theta_\text{current} \mid \text{data})
        &amp;=
        \ln p(\text{data} \mid \theta_\text{proposal})
        -
        \ln p(\text{data} \mid \theta_\text{current})\\\\
        &amp;+
        \ln p(\theta_\text{proposal})
        -
        \ln p(\theta_\text{current})
        \end{aligned}$$

        <p>Substituting our log form expressions for the <strong>likelihood ratio</strong> and the <strong>prior odds</strong>:</p>

        $$\begin{aligned}
        \ln p(\theta_\text{proposal} \mid \text{data})
        -
        \ln p(\theta_\text{current} \mid \text{data})
        &amp;=
        \sum_{i:\,t_i&lt;\tau^\text{current}}
        \!
        \frac{(\text{data}_i-\mu_1^{(\text{current})})^2}
        {2\cdot0.9^2}
        +
        \sum_{i:\,t_i\ge\tau^\text{current}}
        \!
        \frac{(\text{data}_i-\mu_2^{(\text{current})})^2}
        {2\cdot0.9^2}
        \\\\
        &amp;-
        \sum_{i:\,t_i&lt;\tau^\text{proposal}}
        \!
        \frac{(\text{data}_i-\mu_1^{(\text{proposal})})^2}
        {2\cdot0.9^2}
        -
        \sum_{i:\,t_i\ge\tau^\text{proposal}}
        \!
        \frac{(\text{data}_i-\mu_2^{(\text{proposal})})^2}
        {2\cdot0.9^2}
        \\\\
        &amp;+\frac{(\mu_1^{\text{current}}-15.0)^2}{2\cdot5.0^2}
        +\frac{(\mu_2^{\text{current}}-15.0)^2}{2\cdot5.0^2}
        \\\\
        &amp;-\frac{(\mu_1^{\text{proposal}}-15.0)^2}{2\cdot5.0^2}
        -\frac{(\mu_2^{\text{proposal}}-15.0)^2}{2\cdot5.0^2}
        \end{aligned}$$

        <h4>The algorithm revisited</h4>

        <p>Now we know how to compute the posterior odds we can run the algorithm. Recall the process:</p>

        <ol>
            <li>Choose an initial hypothesis for $\theta_\text{current}$ anywhere in the parameter space, e.g.<br><br>
                <ul>
                    <li>$\mu_1^\text{current}$ = 10.0 mg/L</li>
                    <li>$\mu_2^\text{current}$ = 15.0 mg/L</li>
                    <li>$\tau^\text{current}$ = 11.25 hours</li>
                </ul>
            </li>
            <li>Choose a proposal hypothesis $\theta_\text{proposal}$ at random within a region around $\theta_\text{current}$. Any distribution can be used to generate the parameters provided that it's symmetrical (asymmetrical distributions <em>can</em> be used but that requires using a correction term called the Hastings correction, which is beyond the scope of this guide). Common choices are the Normal, Uniform and Cauchy distributions. Using a Uniform distribution with proposal widths of +/- 2 mg/L for the means and +/- 2 hours for $\tau$ might propose this random hypothesis:<br><br>
                <ul>
                    <li>$\mu_1^\text{proposal}$ = 11.2 mg/L</li>
                    <li>$\mu_2^\text{proposal}$ = 14.7 mg/L</li>
                    <li>$\tau^\text{proposal}$ = 12.81 hours</li>
                </ul>
            </li>
            <li>Using the above and the observations in $\text{data}$ calculate the logarithm of the posterior odds using the equation at the end of the previous section.</li>
            <li>
                <p>Decide whether to accept $\theta_\text{current}$ or $\theta_\text{proposal}$ as the value of $\theta_\text{accepted}$. Recall that we accept $\theta_\text{proposal}$ if the posterior odds $\ge1$. We've calculated the <em>logarithm</em> of the posterior odds, so that means we accept $\theta_\text{proposal}$ if the log value $\ge0$.</p>
                <p>If the logarithm of the posterior odds is negative, implying $0\le\text{posterior odds}&lt;1$, we need to accept one of the hypotheses at random. We use an RNG to select a number between 0 and 1 and take the logarithm of that number. If the logarithm of the random number is less than the logarithm of the posterior odds we accept $\theta_\text{proposal}$, otherwise we accept $\theta_\text{current}$.</p>
            </li>
            <li>Record $\theta_\text{accepted}$ as a sample from the posterior distribution</li>
            <li>Jump back to step 2), setting $\theta_\text{current}$ to the value of $\theta_\text{accepted}$</li>
            <li>Repeat 2&ndash;6) until you have enough samples that the posterior distribution is stable.</li>
        </ol>

        <h4>Run the algorithm</h4>

        <p>In this <a href="https://github.com/almostmachines/metropolis-cpd-script" target="_blank">Github repo</a> there's a Python script that will run the full experiment, give it a go.</p>

        <h3>Considerations</h3>

        <h4>Proposal widths</h4>

        <p>We didn't discuss how to select these values. In both of the simulations you can change the proposal width for each parameter in the settings. Try changing these and observe how it affects the exploration of the probability space and the acceptance rate displayed in the results. A common rule of thumb is to tune proposal widths to get an acceptance rate around 20-50% (the optimal depends on the dimensionality and other factors, but this range is a reasonable target).</p>

        <p>If the proposal width is too narrow, you take tiny steps. Each proposal is very close to where you are, so it's almost always accepted (the posterior doesn't change much over small distances). Your acceptance rate is high, but you explore the space slowly — it takes many iterations to move from one region to another. The chain is highly correlated: consecutive samples are nearly identical.</p>

        <p>If the proposal width is too wide, you take big leaps. Most of the time you land somewhere with much lower posterior probability, so you reject and stay put. Your acceptance rate is low, and you spend long stretches stuck in place, occasionally making a large jump. Again, you explore inefficiently.</p>

        <p>The sweet spot is somewhere in between — steps large enough to move meaningfully through the space, but not so large that you're constantly rejected.</p>

        <h4>The initial hypothesis</h4>

        <p>Ideally we would like the initial hypothesis to be within or close to the posterior distribution. For simple problems, visual inspection of the data will often suffice. It may make sense to base it on our prior beliefs if those are informative. Domain knowledge may also help guide selection. A more sophisticated approach would be to use maximum likelihood estimation to find a point close to the posterior mode. Another approach is to do multiple runs, each one starting with a random initial hypotheses. If the multiple runs converge on similar estimates of the posterior distribution this gives confidence that the initial hypothesis is not affecting the results.</p>

        <h2>History</h2>

        <h3>Chess and thermodynamics</h3>

        <div class="textWithImage">
            <div class="textWithImage__text">
                    <p>On the right is the first coauthor of the Metropolis algorithm, <a href="https://en.wikipedia.org/wiki/Nicholas_Metropolis" target="_blank">Nicholas Metropolis</a>, playing a variant of chess against the computer <a href="https://en.wikipedia.org/wiki/MANIAC_I" target="_blank">MANIAC I</a> at the Los Alamos Scientific Laboratory in the 1950s.</p>

                <p>MANIAC ran the first computer aided computation of the <a href="https://en.wikipedia.org/wiki/Equation_of_State_Calculations_by_Fast_Computing_Machines" target="_blank">Metropolis algorithm</a>.</p>

                <p>It was also the first computer to <a href="https://en.wikipedia.org/wiki/Los_Alamos_chess" target="_blank">beat a human</a> at a game of (simplified) chess in 1953. The chess was called anti-clerical chess because there were no bishops!</p>
            </div>

            <picture class="textWithImage__image">
                <img alt="Nicholas Metropolis playing anti-clerical chess against MANIAC I" src="./chess.webp">
                <a href="#" class="photo-attribution" onclick="document.getElementById('attribution-modal').showModal(); return false;">attribution</a>
            </picture>

            <dialog id="attribution-modal" class="attribution-dialog" onclick="if(event.target===this)this.close()">
                <div class="attribution-dialog__content">
                    <button class="attribution-dialog__close" onclick="this.closest('dialog').close()">&times;</button>
                    <p>Unless otherwise indicated, this information has been authored by an employee or employees of the Los Alamos National Security, LLC (LANS), operator of the Los Alamos National Laboratory under Contract No. DE-AC52-06NA25396 with the U.S. Department of Energy. The U.S. Government has rights to use, reproduce, and distribute this information. The public may copy and use this information without charge, provided that this Notice and any statement of authorship are reproduced on all copies. Neither the Government nor LANS makes any warranty, express or implied, or assumes any liability or responsibility for the use of this information.</p>
                </div>
            </dialog>
        </div>

        <h3>Metropolis-Hastings</h3>

        <p>In 1970, <a href="https://en.wikipedia.org/wiki/W._K._Hastings" target="_blank">Wilfred Hastings</a> extended the Metropolis algorithm to handle asymmetrical proposal distributions. This generalised algorithm became known as the <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm" target="_blank">Metropolis-Hastings algorithm</a>.</p>
    </article>

    <script>
    (function() {
        const nav = document.getElementById('floating-nav');
        const list = document.getElementById('floating-nav-list');
        const toggle = document.getElementById('floating-nav-toggle');
        const headings = document.querySelectorAll('article h1, article h2, article h3, article h4, article h5, article h6');

        // Build nav items with metadata
        var items = [];
        headings.forEach(function(h, i) {
            if (!h.id) h.id = 'heading-' + i;
            var level = parseInt(h.tagName[1]);
            var li = document.createElement('li');
            li.className = 'floating-nav__item floating-nav__item--h' + level;
            if (level >= 4) li.classList.add('floating-nav__item--collapsible');
            var a = document.createElement('a');
            a.href = '#' + h.id;
            a.textContent = h.textContent;
            a.addEventListener('click', function() {
                if (window.innerWidth < 1600) {
                    nav.classList.remove('floating-nav--open');
                    toggle.classList.remove('floating-nav-toggle--active');
                }
            });
            li.appendChild(a);
            list.appendChild(li);
            items.push({ li: li, level: level, id: h.id });
        });

        // For each collapsible item (h4/h5), find its parent.
        // Parent of h4 = nearest preceding h3. Parent of h5 = nearest preceding h4.
        items.forEach(function(item, idx) {
            if (item.level < 4) return;
            var parentLevel = item.level - 1;
            for (var p = idx - 1; p >= 0; p--) {
                if (items[p].level === parentLevel) {
                    item.parentIdx = p;
                    break;
                }
                if (items[p].level < parentLevel) break;
            }
        });

        // Second pass: build sibling groups now that all parentIdx values are set
        items.forEach(function(item, idx) {
            if (item.level < 4) return;
            item.siblingGroup = [];
            for (var s = 0; s < items.length; s++) {
                if (items[s].level === item.level && items[s].parentIdx === item.parentIdx) {
                    item.siblingGroup.push(s);
                }
            }
        });

        // Mark parents that have collapsible children with an expand icon
        var parentsWithChildren = {};
        items.forEach(function(item) {
            if (item.parentIdx !== undefined) {
                parentsWithChildren[item.parentIdx] = true;
            }
        });
        Object.keys(parentsWithChildren).forEach(function(idx) {
            items[idx].li.classList.add('floating-nav__item--has-children');
        });

        function updateVisibility(activeId) {
            // Find index of active item
            var activeIdx = -1;
            for (var i = 0; i < items.length; i++) {
                if (items[i].id === activeId) { activeIdx = i; break; }
            }

            items.forEach(function(item, idx) {
                // Update active class
                var a = item.li.querySelector('a');
                a.classList.toggle('floating-nav__link--active', idx === activeIdx);

                if (item.level < 4) {
                    item.li.classList.remove('floating-nav__item--collapsed');
                    // Toggle expanded state on parents
                    if (parentsWithChildren[idx]) {
                        var hasVisibleChild = false;
                        for (var c = 0; c < items.length; c++) {
                            if (items[c].parentIdx === idx && !items[c].li.classList.contains('floating-nav__item--collapsed')) {
                                // Will be set below, so check prospectively
                            }
                        }
                    }
                    return;
                }

                // Collapsible item: show if active item is self, parent, sibling,
                // or a child of self/sibling (so h4 siblings stay visible when an h5 is active)
                var show = false;
                if (activeIdx >= 0) {
                    if (activeIdx === idx) show = true;
                    else if (item.parentIdx !== undefined && activeIdx === item.parentIdx) show = true;
                    else if (item.siblingGroup && item.siblingGroup.indexOf(activeIdx) !== -1) show = true;
                    // Check if active item's parent (or any ancestor) is self or a sibling
                    else {
                        var ancestor = items[activeIdx];
                        while (ancestor && ancestor.parentIdx !== undefined) {
                            ancestor = items[ancestor.parentIdx];
                            if (ancestor === item) { show = true; break; }
                            if (item.siblingGroup && item.siblingGroup.indexOf(items.indexOf(ancestor)) !== -1) { show = true; break; }
                        }
                    }
                }
                item.li.classList.toggle('floating-nav__item--collapsed', !show);
            });

            // Update expanded icon state on parents
            Object.keys(parentsWithChildren).forEach(function(pIdx) {
                var expanded = false;
                for (var c = 0; c < items.length; c++) {
                    if (items[c].parentIdx === parseInt(pIdx) && !items[c].li.classList.contains('floating-nav__item--collapsed')) {
                        expanded = true;
                        break;
                    }
                }
                items[pIdx].li.classList.toggle('floating-nav__item--expanded', expanded);
            });
        }

        // Initial state: collapse all h4/h5
        updateVisibility(null);

        toggle.addEventListener('click', function() {
            nav.classList.toggle('floating-nav--open');
            toggle.classList.toggle('floating-nav-toggle--active');
        });

        document.addEventListener('click', function(e) {
            if (window.innerWidth < 1600 && nav.classList.contains('floating-nav--open')) {
                if (!nav.contains(e.target) && e.target !== toggle && !toggle.contains(e.target)) {
                    nav.classList.remove('floating-nav--open');
                    toggle.classList.remove('floating-nav-toggle--active');
                }
            }
        });

        // Highlight current section and update collapsible visibility
        var observer = new IntersectionObserver(function(entries) {
            entries.forEach(function(entry) {
                if (entry.isIntersecting) {
                    updateVisibility(entry.target.id);
                }
            });
        }, { rootMargin: '0px 0px -70% 0px', threshold: 0 });

        headings.forEach(function(h) { observer.observe(h); });
    })();
    </script>

    <footer class="site-footer">
        <div class="footer-divider"></div>
        <div class="footer-content">
            <span class="footer-copy">&copy; John King 2026</span>
            <span class="footer-links">
                <a href="https://github.com/almostmachines" target="_blank" rel="noopener">GitHub</a>
                <span class="footer-dot">·</span>
                <a href="https://almostmachines.dev/" target="_blank" rel="noopener">Contact</a>
            </span>
        </div>
    </footer>

    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
</body>
</html>
